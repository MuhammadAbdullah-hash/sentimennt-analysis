{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2CVdhPDftfdl"
      ],
      "authorship_tag": "ABX9TyP/X7alC4B6+9s2qjHfUrWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadAbdullah-hash/sentimennt-analysis/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-uTE84rc6H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import keras\n",
        "import sklearn.model_selection\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CVdhPDftfdl",
        "colab_type": "text"
      },
      "source": [
        "# **Data is pre-processed using Following code snipet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baaqk1RYtQ1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pathlib\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# direct = [ # ##### PUT IN DIRECTORY OF FOLDER CONTAINING POS AND NEG COMMENTS SEPRATELY ]\n",
        "\n",
        "# lis_pos_train  , lis_neg_train = [] , []\n",
        "# def process(dire , itr , n):\n",
        "# \tfor path in pathlib.Path(dire).iterdir():\n",
        "# \t    if path.is_file():\n",
        "# \t        with open(path, \"rb\") as f:\n",
        "# \t        \tz = f.read()\n",
        "# \t        \titr.append( (z , n) )\n",
        "\n",
        "# for i in range(len(direct)):\n",
        "# \tif i == 0:\n",
        "# \t\tprocess( direct[i] , lis_neg_train , i  )\n",
        "# \tif i == 1:\n",
        "# \t\tprocess( direct[i] , lis_pos_train , i)\t\n",
        "# text_pos , text_neg , target_pos , target_neg = [] , [] , [] , []\n",
        "\n",
        "# for i in range( len(lis_pos_train) )  :\n",
        "# \ttext_pos.append( lis_pos_train[i][0] )\n",
        "# \ttext_neg.append( lis_neg_train[i][0] )\n",
        "\n",
        "# \ttarget_pos.append( lis_pos_train[i][-1] )\n",
        "# \ttarget_neg.append( lis_neg_train[i][-1] )\n",
        "\t\n",
        "# for j in range(len( target_pos ) ):\n",
        "# \ttext_pos.append( text_neg[i] )\n",
        "# \ttarget_pos.append(  target_neg[i]  )\n",
        "\n",
        "# dic = { 'Text' : text_pos , 'Target' : target_pos  }\n",
        "# result = pd.DataFrame( dic )\n",
        "# result.to_csv('my_data.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STZhphUduH-o",
        "colab_type": "text"
      },
      "source": [
        "# **Project**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61BzjBCDuFim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "0dadbb2c-a490-42f7-b1d7-3a1edd294122"
      },
      "source": [
        "data = pd.read_csv('new_dat.csv')\n",
        "print( data.head() )\n",
        "print( data.isnull().sum() )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                               Text  Target\n",
            "0           0  b'Bromwell High is a cartoon comedy. It ran at...       1\n",
            "1           1  b'Homelessness (or Houselessness as George Car...       1\n",
            "2           2  b'Brilliant over-acting by Lesley Ann Warren. ...       1\n",
            "3           3  b'This is easily the most underrated film inn ...       1\n",
            "4           4  b'This is not the typical Mel Brooks film. It ...       1\n",
            "Unnamed: 0    0\n",
            "Text          0\n",
            "Target        0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHj6pTav6-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1c9819dd-b670-462d-bd00-472ca2d7890a"
      },
      "source": [
        "text = np.array( data['Text'] )\n",
        "target = np.array( data['Target'] )\n",
        "print(text.shape , target.shape)\n",
        "\n",
        "# ################# Spliting - DATA ############### #\n",
        "\n",
        "x_train , y_test , x_lab , y_lab = sklearn.model_selection.train_test_split(text , target , test_size = 0.1)\n",
        "\n",
        "# x_train , y_test =  text[ : 20000] , text[20000 : ]\n",
        "# x_lab , y_lab = target[ : 20000] , target[ 20000 : ]\n",
        "\n",
        "print(x_train.shape , y_test.shape)\n",
        "print(x_lab.shape , y_lab.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n",
            "(22500,) (2500,)\n",
            "(22500,) (2500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYN-83lpwPrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer( num_words=10000 , oov_token='<OOV>' )\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# for i in word_index.items():\n",
        "#   print(i)\n",
        "\n",
        "# ###### We make sequence / padding of testing and training data ######### #\n",
        "\n",
        "sequence_train = tokenizer.texts_to_sequences(x_train)\n",
        "sequence_test = tokenizer.texts_to_sequences(y_test)\n",
        "\n",
        "pad_train = pad_sequences(sequence_train , padding = 'pre') \n",
        "pad_test = pad_sequences(sequence_test , padding = 'pre')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbZamMXv0wxO",
        "colab_type": "text"
      },
      "source": [
        "# **Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KV06_fYyRNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fbdb4e5a-ae98-4f57-fd58-7e19f98645b5"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add( keras.layers.Embedding( 10000 , 16) ) # Creates vectors in 16 dimensions\n",
        "model.add( keras.layers.GlobalAveragePooling1D() ) # fIND resultant vector\n",
        "model.add( keras.layers.Dense( 24 , activation='relu') )\n",
        "model.add( keras.layers.Dense( 1 , activation='sigmoid') )\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 160,433\n",
            "Trainable params: 160,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaE--Mx114XX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "27396858-1a19-4f94-e7ce-6000fda57434"
      },
      "source": [
        "model.fit( pad_train , x_lab , epochs=10 , validation_data=(pad_test , y_lab) )\n",
        "loss,  acc = model.evaluate(pad_test , y_lab)\n",
        "\n",
        "print(loss , acc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 22500 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            "22500/22500 [==============================] - 4s 168us/step - loss: 0.6874 - accuracy: 0.5578 - val_loss: 0.6522 - val_accuracy: 0.7384\n",
            "Epoch 2/10\n",
            "22500/22500 [==============================] - 4s 164us/step - loss: 0.5506 - accuracy: 0.7728 - val_loss: 0.4438 - val_accuracy: 0.7964\n",
            "Epoch 3/10\n",
            "22500/22500 [==============================] - 4s 165us/step - loss: 0.3801 - accuracy: 0.8567 - val_loss: 0.3502 - val_accuracy: 0.8548\n",
            "Epoch 4/10\n",
            "22500/22500 [==============================] - 4s 164us/step - loss: 0.3077 - accuracy: 0.8864 - val_loss: 0.3176 - val_accuracy: 0.8772\n",
            "Epoch 5/10\n",
            "22500/22500 [==============================] - 4s 166us/step - loss: 0.2734 - accuracy: 0.8955 - val_loss: 0.3266 - val_accuracy: 0.8692\n",
            "Epoch 6/10\n",
            "22500/22500 [==============================] - 4s 165us/step - loss: 0.2492 - accuracy: 0.9053 - val_loss: 0.3133 - val_accuracy: 0.8868\n",
            "Epoch 7/10\n",
            "22500/22500 [==============================] - 4s 168us/step - loss: 0.2291 - accuracy: 0.9138 - val_loss: 0.3148 - val_accuracy: 0.8812\n",
            "Epoch 8/10\n",
            "22500/22500 [==============================] - 4s 167us/step - loss: 0.2138 - accuracy: 0.9198 - val_loss: 0.3154 - val_accuracy: 0.8852\n",
            "Epoch 9/10\n",
            "22500/22500 [==============================] - 4s 166us/step - loss: 0.1996 - accuracy: 0.9255 - val_loss: 0.3263 - val_accuracy: 0.8804\n",
            "Epoch 10/10\n",
            "22500/22500 [==============================] - 4s 166us/step - loss: 0.1870 - accuracy: 0.9312 - val_loss: 0.3309 - val_accuracy: 0.8860\n",
            "2500/2500 [==============================] - 0s 45us/step\n",
            "0.3309056573867798 0.8859999775886536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLJWELY02JJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"MODEL.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSVnGUwa62J6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "44cc62c5-2681-4bc7-91e4-f5190faf5af9"
      },
      "source": [
        "predictions = model.predict( pad_test )\n",
        "predictions = np.round(predictions , 0)\n",
        "for i in range(50):\n",
        "  print( predictions[i][0] , y_lab[i] )\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 1\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "1.0 1\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "1.0 1\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.0 0\n",
            "0.0 0\n",
            "1.0 1\n",
            "0.0 0\n",
            "1.0 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzWkR_qQ_dCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "46b30ca0-91ae-457d-e9b8-f623386d8fcc"
      },
      "source": [
        "sen = 'I am not satisfied with thiis movie but also little bit satisfied'\n",
        "seq = tokenizer.texts_to_sequences([sen])\n",
        "pad = pad_sequences(seq , padding='pre')\n",
        "\n",
        "result = model.predict(pad)\n",
        "\n",
        "print(result)\n",
        "result = np.round(model.predict(pad) )\n",
        "print(int(result[0]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-0x8PVL6wNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import load_model\n",
        "# model = load_model( 'MODEL.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}